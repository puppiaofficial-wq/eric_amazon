import streamlit as st
import asyncio
import pandas as pd
from datetime import datetime
import json
import os
from amazon_review_scraper import AmazonReviewScraper

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Amazon Review Scraper",
    page_icon="ğŸ›’",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'scraper' not in st.session_state:
    st.session_state.scraper = None
if 'is_running' not in st.session_state:
    st.session_state.is_running = False
if 'reviews' not in st.session_state:
    st.session_state.reviews = []

def main():
    st.title("ğŸ›’ Amazon Review Scraper")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ë¡œê·¸ì¸ ì •ë³´
        st.subheader("Amazon ë¡œê·¸ì¸ ì •ë³´")
        email = st.text_input("ì´ë©”ì¼", value="puppiaofficial@gmail.com")
        password = st.text_input("ë¹„ë°€ë²ˆí˜¸", value="Xxyy0208!", type="password")
        
        # ìƒí’ˆ ì •ë³´
        st.subheader("ìƒí’ˆ ì •ë³´")
        product_url = st.text_input(
            "ìƒí’ˆ URL", 
            value="https://www.amazon.com/-/ko/dp/B00390BGLK",
            help="Amazon ìƒí’ˆ í˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        max_reviews = st.number_input(
            "ìµœëŒ€ ë¦¬ë·° ìˆ˜", 
            min_value=10, 
            max_value=1000, 
            value=50,
            help="ìˆ˜ì§‘í•  ìµœëŒ€ ë¦¬ë·° ê°œìˆ˜ (ê¶Œì¥: 50-200ê°œ)"
        )
        
        # ì˜µì…˜
        st.subheader("ì˜µì…˜")
        headless = st.checkbox("ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰", value=True, help="ë¸Œë¼ìš°ì € ì°½ì„ ìˆ¨ê¸°ê³  ì‹¤í–‰")
        save_csv = st.checkbox("CSV ì €ì¥", value=True)
        save_json = st.checkbox("JSON ì €ì¥", value=True)
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“Š ë¦¬ë·° ìˆ˜ì§‘")
        
        # ìˆ˜ì§‘ ë²„íŠ¼
        if st.button("ğŸš€ ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘", disabled=st.session_state.is_running):
            if validate_inputs(email, password, product_url):
                st.session_state.is_running = True
                st.rerun()
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if st.session_state.is_running:
            with st.spinner("ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘..."):
                try:
                    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
                    reviews = asyncio.run(scrape_reviews_async(
                        email, password, product_url, max_reviews, headless
                    ))
                    
                    if reviews:
                        st.session_state.reviews = reviews
                        st.success(f"âœ… ì´ {len(reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
                        
                        # íŒŒì¼ ì €ì¥
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        
                        if save_csv:
                            csv_file = f"amazon_reviews_{timestamp}.csv"
                            df = pd.DataFrame(reviews)
                            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
                            st.info(f"CSV íŒŒì¼ ì €ì¥: {csv_file}")
                        
                        if save_json:
                            json_file = f"amazon_reviews_{timestamp}.json"
                            with open(json_file, 'w', encoding='utf-8') as f:
                                json.dump(reviews, f, ensure_ascii=False, indent=2)
                            st.info(f"JSON íŒŒì¼ ì €ì¥: {json_file}")
                    
                    else:
                        st.error("âŒ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                
                finally:
                    st.session_state.is_running = False
    
    with col2:
        st.header("ğŸ“ˆ í†µê³„")
        
        if st.session_state.reviews:
            reviews = st.session_state.reviews
            
            # ê¸°ë³¸ í†µê³„
            st.metric("ì´ ë¦¬ë·° ìˆ˜", len(reviews))
            
            # í‰ì  í†µê³„
            ratings = [r['rating'] for r in reviews if r['rating'] > 0]
            if ratings:
                avg_rating = sum(ratings) / len(ratings)
                st.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}")
                
                # í‰ì  ë¶„í¬
                rating_dist = pd.Series(ratings).value_counts().sort_index()
                st.bar_chart(rating_dist)
            
            # ì¸ì¦ëœ êµ¬ë§¤ ë¹„ìœ¨
            verified = sum(1 for r in reviews if r['verified_purchase'])
            verified_pct = (verified / len(reviews)) * 100
            st.metric("ì¸ì¦ëœ êµ¬ë§¤", f"{verified_pct:.1f}%")
    
    # ë¦¬ë·° ë°ì´í„° í‘œì‹œ
    if st.session_state.reviews:
        st.header("ğŸ“ ìˆ˜ì§‘ëœ ë¦¬ë·°")
        
        # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(st.session_state.reviews)
        
        # í•„í„°ë§ ì˜µì…˜
        col1, col2, col3 = st.columns(3)
        with col1:
            min_rating = st.selectbox("ìµœì†Œ í‰ì ", [0, 1, 2, 3, 4, 5], index=0)
        with col2:
            verified_only = st.checkbox("ì¸ì¦ëœ êµ¬ë§¤ë§Œ")
        with col3:
            show_count = st.number_input("í‘œì‹œí•  ë¦¬ë·° ìˆ˜", 1, len(df), min(10, len(df)))
        
        # í•„í„° ì ìš©
        filtered_df = df.copy()
        if min_rating > 0:
            filtered_df = filtered_df[filtered_df['rating'] >= min_rating]
        if verified_only:
            filtered_df = filtered_df[filtered_df['verified_purchase'] == True]
        
        # ë°ì´í„° í‘œì‹œ
        st.dataframe(
            filtered_df.head(show_count)[['reviewer_name', 'rating', 'title', 'date', 'content']],
            use_container_width=True
        )
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            csv_data = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                csv_data,
                f"amazon_reviews_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                "text/csv"
            )
        
        with col2:
            json_data = json.dumps(st.session_state.reviews, ensure_ascii=False, indent=2)
            st.download_button(
                "ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ",
                json_data,
                f"amazon_reviews_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "application/json"
            )

def validate_inputs(email, password, product_url):
    """ì…ë ¥ê°’ ê²€ì¦"""
    if not email.strip():
        st.error("ì´ë©”ì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    if not password.strip():
        st.error("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    if not product_url.strip():
        st.error("ìƒí’ˆ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    if 'amazon.com' not in product_url:
        st.error("ì˜¬ë°”ë¥¸ Amazon URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    return True

async def scrape_reviews_async(email, password, product_url, max_reviews, headless):
    """ë¹„ë™ê¸° ë¦¬ë·° ìˆ˜ì§‘"""
    scraper = AmazonReviewScraper()
    
    try:
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...")
        progress_bar.progress(10)
        
        await scraper.start_browser(headless=headless)
        
        status_text.text("ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ì¤‘...")
        progress_bar.progress(30)
        
        if not await scraper.check_login_status():
            status_text.text("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.")
            # ì›¹ í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ ë¡œê·¸ì¸ ì•ˆë‚´ë§Œ í‘œì‹œ
            st.warning("âš ï¸ ë¸Œë¼ìš°ì €ì—ì„œ Amazonì— ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”. (ì•½ 30ì´ˆ í›„ ìë™ìœ¼ë¡œ ì¬í™•ì¸)")
            await asyncio.sleep(30)
            
            if not await scraper.check_login_status():
                st.error("ë¡œê·¸ì¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return []
        
        status_text.text("ë¦¬ë·° ìˆ˜ì§‘ ì¤‘...")
        progress_bar.progress(50)
        
        reviews = await scraper.get_all_reviews(product_url, max_reviews)
        
        progress_bar.progress(100)
        status_text.text("ìˆ˜ì§‘ ì™„ë£Œ!")
        
        return reviews
        
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []
    
    finally:
        try:
            await scraper.close_browser()
        except:
            pass

if __name__ == "__main__":
    main()
